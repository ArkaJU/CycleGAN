# Image-colorization-using-CycleGAN

# Introduction

Automatic image colorization has been a popular image-to-image translation problem of significant interest for several practical application areas including restoration of aged or degraded images. This project attempts to utilize CycleGANs to colorize grayscale images back to their colorful RGB form.

# Overview

Image-to-image  translation  is  a  class  of  vision  andgraphics problems where the goal is to learn the mapping
between an input image and an output image using a training set of aligned image pairs. But for many tasks, paired training data may not be available like this problem of image colorization. This is where the power of CycleGAN becomes apparent. Superiority of CycleGAN has been demonstrated on several tasks where paired training data hardly exist, e.g., in object transfiguration and painting style and season transfer

# Model

Generative Adversarial Networks(GANs) are composed of two models:
1. Generator: Aims to generate new data similar to the expected one. The Generator could be related to a human art forger, which creates fake works of art.
2. Discriminator: It's goal is to recognize if an input data is ‘real’ — belongs to the original dataset — or if it is ‘fake’ — generated by a forger. In this scenario, a Discriminator is analogous to  an art expert, who tries to detect artworks as truthful or fraud.

The CycleGAN consists of 2 generators and discriminators. One generator maps from domain A to B and the other one, from B to A.
They compete with their corresponding adversarial discriminators.


To regularize the model, the authors introduce the constraint of cycle-consistency - if we transform from source distribution to target and then back again to source distribution, we should get samples from our source distribution.

![](images/CycleLoss.png)
